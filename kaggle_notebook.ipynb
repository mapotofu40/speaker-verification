{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9920101,"sourceType":"datasetVersion","datasetId":6096635},{"sourceId":11565412,"sourceType":"datasetVersion","datasetId":7251391},{"sourceId":11688515,"sourceType":"datasetVersion","datasetId":7336252},{"sourceId":11776227,"sourceType":"datasetVersion","datasetId":7393408},{"sourceId":5539168,"sourceType":"datasetVersion","datasetId":3192482}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ba995531","cell_type":"markdown","source":"# Speaker Verification with ECAPA-TDNN on Kaggle GPU\n\nThis notebook implements speaker verification using the ECAPA-TDNN architecture on Kaggle's GPU.\n\n## Table of Contents\n1. Setup and Installation\n2. Repository and Environment Configuration\n3. Dataset and Model Configuration\n4. Model Training\n5. Optional: MUSAN Augmentation Validation","metadata":{}},{"id":"29a7752a","cell_type":"code","source":"# Install required packages\n!pip install torch torchaudio PyYAML soundfile librosa wandb\n!pip install matplotlib numpy tqdm\n\nprint(\"Package installation complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:06.217665Z","iopub.execute_input":"2025-06-01T19:47:06.217992Z","iopub.status.idle":"2025-06-01T19:47:12.504887Z","shell.execute_reply.started":"2025-06-01T19:47:06.217966Z","shell.execute_reply":"2025-06-01T19:47:12.504168Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->soundfile) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->soundfile) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->soundfile) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->soundfile) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nPackage installation complete!\n","output_type":"stream"}],"execution_count":92},{"id":"7f54167d","cell_type":"code","source":"# Setup working directory and clone repository\nimport os\nimport sys\nfrom pathlib import Path\n\n# Start fresh in working directory\n%cd /kaggle/working\n!rm -rf speaker-verification\n\n# Clone repository\n!git clone https://github.com/mapotofu40/speaker-verification.git\n\n# Move config.py to avoid name conflict\n!mv speaker-verification/config.py speaker-verification/global_config.py\n\n# Set up Python path properly\nproject_dir = Path('/kaggle/working/speaker-verification').absolute()\n\n# Clean up sys.path\nsys.path = [p for p in sys.path if 'speaker-verification/speaker-verification' not in p]\n\n# Add project directory to Python path if not already present\nif str(project_dir) not in sys.path:\n    sys.path.insert(0, str(project_dir))\n\n# Change to project directory\nos.chdir(project_dir)\n\nprint(\"\\nDirectory structure:\")\n!ls -R\n\nprint(f\"\\nProject directory: {project_dir}\")\nprint(f\"Current working directory: {os.getcwd()}\")\nprint(f\"\\nPython path:\")\nfor p in sys.path:\n    print(f\"  {p}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:12.506517Z","iopub.execute_input":"2025-06-01T19:47:12.506740Z","iopub.status.idle":"2025-06-01T19:47:13.385945Z","shell.execute_reply.started":"2025-06-01T19:47:12.506720Z","shell.execute_reply":"2025-06-01T19:47:13.385047Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nCloning into 'speaker-verification'...\nremote: Enumerating objects: 56, done.\u001b[K\nremote: Counting objects: 100% (56/56), done.\u001b[K\nremote: Compressing objects: 100% (44/44), done.\u001b[K\nremote: Total 56 (delta 21), reused 45 (delta 10), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (56/56), 35.29 KiB | 5.04 MiB/s, done.\nResolving deltas: 100% (21/21), done.\n\nDirectory structure:\n.:\ncli.py\t ecapa_tdnn\t   kaggle_notebook.ipynb  requirements.txt  train.py\nconfig\t evaluate.py\t   models\t\t  tester\t    utils\ndataset  global_config.py  README.md\t\t  trainer\t    verify.py\n\n./config:\ndefaults.py  __init__.py\n\n./models:\necapa_tdnn.py  feature_extractor.py  __init__.py  modules.py\n\n./utils:\naugment.py  config.py  data.py\t__init__.py  metrics.py  training.py\n\nProject directory: /kaggle/working/speaker-verification\nCurrent working directory: /kaggle/working/speaker-verification\n\nPython path:\n  /kaggle/working/speaker-verification\n  /kaggle/working\n  /kaggle/lib/kagglegym\n  /kaggle/lib\n  /usr/lib/python311.zip\n  /usr/lib/python3.11\n  /usr/lib/python3.11/lib-dynload\n  \n  /usr/local/lib/python3.11/dist-packages\n  /usr/lib/python3/dist-packages\n  /usr/local/lib/python3.11/dist-packages/IPython/extensions\n  /usr/local/lib/python3.11/dist-packages/setuptools/_vendor\n  /root/.ipython\n  /tmp/tmpro502e0_\n","output_type":"stream"}],"execution_count":93},{"id":"4ce5bba5","cell_type":"code","source":"# Import necessary modules\nimport torch\nimport torch.nn.functional as F\nimport sys\nimport logging\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Clear any remaining path duplicates\nsys.path = list(dict.fromkeys(sys.path))\n\n# Verify imports work\ntry:\n    from config.defaults import BASE_CONFIG\n    from models.ecapa_tdnn import SpeakerVerificationModel\n    from models.feature_extractor import FeatureExtractor\n    from utils.data import VietnamCelebDataset, ValidationPairDataset, collate_fn\n    from utils.training import train_model\n    from utils.metrics import compute_eer, cosine_similarity\n    from tqdm import tqdm\n    print(\"All modules imported successfully!\")\n    \nexcept ImportError as e:\n    print(f\"Import error: {e}\")\n    print(\"\\nCurrent directory structure:\")\n    !pwd\n    !ls -R\n    print(f\"\\nPython path:\")\n    for p in sys.path:\n        print(f\"  {p}\")\n    raise\n\n# Verify GPU availability\nprint(f\"\\nGPU available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:13.387149Z","iopub.execute_input":"2025-06-01T19:47:13.387415Z","iopub.status.idle":"2025-06-01T19:47:13.399342Z","shell.execute_reply.started":"2025-06-01T19:47:13.387391Z","shell.execute_reply":"2025-06-01T19:47:13.398826Z"}},"outputs":[{"name":"stdout","text":"All modules imported successfully!\n\nGPU available: True\nGPU device: Tesla P100-PCIE-16GB\n","output_type":"stream"}],"execution_count":94},{"id":"2ba27bd8","cell_type":"markdown","source":"## Weights & Biases Setup\n\nBefore running the training, you need to:\n1. Create a free account at https://wandb.ai if you haven't already\n2. Get your API key from https://wandb.ai/authorize\n3. When you run the cell below, you'll see a prompt that says \"wandb: Please enter your credentials to login to wandb\"\n4. Paste your API key and press Enter\n\nYour API key will be securely stored for future use.","metadata":{}},{"id":"a2f25bc6","cell_type":"code","source":"# Configure paths for Kaggle\nconfig = BASE_CONFIG.copy()\nconfig['paths'].update({\n    'checkpoint_dir': '/kaggle/working/checkpoints',\n    'log_dir': '/kaggle/working/logs',\n    'cache_dir': '/kaggle/working/cache'\n})\n\n# Create necessary directories\nfor path in config['paths'].values():\n    Path(path).mkdir(parents=True, exist_ok=True)\n\n# Login to Weights & Biases\nimport wandb\n\n# This will prompt you to enter your API key\nwandb.login(key = \"890ec82b435e34992eb8da6f0b05ae313d701245\")\n\n# Initialize wandb run\nwandb.init(\n    project=\"speaker-verification\",\n    config={\n        \"architecture\": \"ECAPA-TDNN\",\n        \"dataset\": \"VietnamCeleb\",\n        **config['training'],  # Add training config\n        **config['audio'],     # Add audio processing config\n        **config['model']      # Add model architecture config\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:13.401129Z","iopub.execute_input":"2025-06-01T19:47:13.401324Z","iopub.status.idle":"2025-06-01T19:47:20.049699Z","shell.execute_reply.started":"2025-06-01T19:47:13.401309Z","shell.execute_reply":"2025-06-01T19:47:20.048941Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">vibrant-firebrand-13</strong> at: <a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/0xixvidl' target=\"_blank\">https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/0xixvidl</a><br> View project at: <a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification' target=\"_blank\">https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification</a><br>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250601_194628-0xixvidl/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/speaker-verification/wandb/run-20250601_194713-qggcy8qu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/qggcy8qu' target=\"_blank\">brisk-waterfall-14</a></strong> to <a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification' target=\"_blank\">https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/qggcy8qu' target=\"_blank\">https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/qggcy8qu</a>"},"metadata":{}},{"execution_count":95,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/mapotofu-hanoi-university-of-science-and-technology/speaker-verification/runs/qggcy8qu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7acaa374d690>"},"metadata":{}}],"execution_count":95},{"id":"8808d731","cell_type":"code","source":"# MUSAN dataset configuration\nmusan_config = {\n    'data_root': '/kaggle/input/musan-dataset/musan',  # Update this path to your MUSAN dataset location\n    'noise_dir': 'noise',\n    'music_dir': 'music',\n    'speech_dir': 'speech',\n    'sample_rate': config['audio']['sample_rate'],\n    'min_snr_db': 5,\n    'max_snr_db': 20\n}\n\n# Update augmentation configuration with MUSAN parameters\naugment_config = {\n    'enabled': True,\n    'speed_perturb': True,\n    'musan_path': musan_config['data_root'],\n    'noise_prob': 0.6,  # Probability of applying noise augmentation\n    'noise_types': {\n        'noise': 0.3,  # background noise probability (maps to noise_dir)\n        'music': 0.4,  # music interference probability (maps to music_dir)\n        'speech': 0.3  # speech/babble noise probability (maps to speech_dir)\n    },\n    'noise_snr_range': [musan_config['min_snr_db'], musan_config['max_snr_db']],  # Use correct parameter name\n    'reverb_prob': 0.5,\n    'musan_noise_prob': 0.6  # Probability of using MUSAN noise vs. Gaussian noise\n}\n\n# Validate MUSAN paths\nmusan_path_map = {\n    'noise': os.path.join(musan_config['data_root'], musan_config['noise_dir']),\n    'music': os.path.join(musan_config['data_root'], musan_config['music_dir']),\n    'speech': os.path.join(musan_config['data_root'], musan_config['speech_dir'])\n}\n\nfor noise_type, path in musan_path_map.items():\n    if not os.path.exists(path):\n        logger.warning(f\"MUSAN {noise_type} path does not exist: {path}\")\n    else:\n        logger.info(f\"MUSAN {noise_type} path validated: {path}\")\n\n# Update wandb config with MUSAN parameters\nwandb.config.update({\n    'musan': {\n        'noise_prob': augment_config['noise_prob'],\n        'noise_types': list(augment_config['noise_types'].keys()),\n        'noise_snr_range': augment_config['noise_snr_range']\n    }\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:49:28.410465Z","iopub.execute_input":"2025-06-01T19:49:28.410758Z","iopub.status.idle":"2025-06-01T19:49:28.421337Z","shell.execute_reply.started":"2025-06-01T19:49:28.410738Z","shell.execute_reply":"2025-06-01T19:49:28.420742Z"}},"outputs":[],"execution_count":102},{"id":"f86ecb45","cell_type":"code","source":"# Dataset configuration\ndata_config = {\n    'data_root': '/kaggle/input/vietnam-celeb-dataset/full-dataset',  # Update with your dataset path\n    'metadata_file': '/kaggle/input/vietnam-celeb-dataset/full-dataset/speaker-metadata.tsv',\n    'train_utterance_file': '/kaggle/input/asv-output/cleaned_utterances.txt',\n    'val_easy_utterance_file': '/kaggle/input/vietnam-celeb-dataset/vietnam-celeb-e.txt',\n    'val_hard_utterance_file': '/kaggle/input/vietnam-celeb-dataset/vietnam-celeb-h.txt'\n}\n\n# Create feature extractor\nfeature_extractor = FeatureExtractor(\n    sample_rate=config['audio']['sample_rate'],\n    n_mels=config['audio']['n_mels']\n)\n\n# Create datasets\ntrain_dataset = VietnamCelebDataset(\n    data_root=data_config['data_root'],\n    metadata_file=data_config['metadata_file'],\n    utterance_file=data_config['train_utterance_file'],\n    feature_extractor=feature_extractor,\n    cache_dir=config['paths']['cache_dir'],\n    use_cache=config['cache']['enabled'],\n    augment=augment_config['enabled'],\n    augment_config=augment_config,  # Now includes MUSAN configuration\n    musan_path=augment_config['musan_path']  # Add MUSAN path\n)\n\n# Create validation datasets with the new ValidationPairDataset\nval_easy_dataset = ValidationPairDataset(\n    data_root=data_config['data_root'],\n    metadata_file=data_config['metadata_file'],\n    pair_file=data_config['val_easy_utterance_file'],\n    feature_extractor=feature_extractor,\n    cache_dir=config['paths']['cache_dir'],\n    use_cache=config['cache']['enabled']\n)\n\nval_hard_dataset = ValidationPairDataset(\n    data_root=data_config['data_root'],\n    metadata_file=data_config['metadata_file'],\n    pair_file=data_config['val_hard_utterance_file'],\n    feature_extractor=feature_extractor,\n    cache_dir=config['paths']['cache_dir'],\n    use_cache=config['cache']['enabled']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:49:31.961132Z","iopub.execute_input":"2025-06-01T19:49:31.961407Z","iopub.status.idle":"2025-06-01T19:49:33.076752Z","shell.execute_reply.started":"2025-06-01T19:49:31.961388Z","shell.execute_reply":"2025-06-01T19:49:33.076043Z"}},"outputs":[],"execution_count":103},{"id":"8900e932","cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# Create data loaders\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=config['training']['batch_size'],\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=2,  # Reduce for Kaggle\n    pin_memory=True\n)\n\n# Create data loaders with the new validation datasets\nval_easy_loader = DataLoader(\n    val_easy_dataset,\n    batch_size=config['training']['batch_size'],\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=2,  # Reduce for Kaggle\n    pin_memory=True\n)\n\nval_hard_loader = DataLoader(\n    val_hard_dataset,\n    batch_size=config['training']['batch_size'],\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=2,  # Reduce for Kaggle\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:49:36.045548Z","iopub.execute_input":"2025-06-01T19:49:36.045851Z","iopub.status.idle":"2025-06-01T19:49:36.092294Z","shell.execute_reply.started":"2025-06-01T19:49:36.045829Z","shell.execute_reply":"2025-06-01T19:49:36.091492Z"}},"outputs":[],"execution_count":104},{"id":"7bcf8611","cell_type":"code","source":"print(\"Setting up model training...\")\n# Initialize optimizer, criterion and move model to device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nmodel = model.to(device)\n\n# Initialize optimizer and scheduler\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=config['training']['learning_rate'],\n    weight_decay=config['training']['weight_decay']\n)\n\n# Learning rate scheduler\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=config['training']['num_epochs']\n)\n\n# Loss criterion for training\ncriterion = torch.nn.CrossEntropyLoss()\n\nprint(\"Model training setup complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:49:38.830572Z","iopub.execute_input":"2025-06-01T19:49:38.830843Z","iopub.status.idle":"2025-06-01T19:49:38.848595Z","shell.execute_reply.started":"2025-06-01T19:49:38.830821Z","shell.execute_reply":"2025-06-01T19:49:38.847812Z"}},"outputs":[{"name":"stdout","text":"Setting up model training...\nUsing device: cuda\nModel training setup complete!\n","output_type":"stream"}],"execution_count":105},{"id":"d0f34d04","cell_type":"code","source":"# Create model\nmodel = SpeakerVerificationModel(\n    input_dim=config['audio']['n_mels'],\n    channels=config['model']['channels'],\n    embedding_dim=config['model']['embedding_dim'],\n    num_blocks=config['model']['num_blocks'],\n    num_speakers=len(train_dataset.speaker_to_idx)\n)\n\n# Watch model in wandb\nwandb.watch(model)\n\n# Validation function to compute EER\ndef validate_eer(model, val_loader, device):\n    \n\n\n\n    model.eval()\n    all_scores = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            features1 = batch['features1'].to(device)\n            features2 = batch['features2'].to(device)\n            labels = batch['label'].to(device)\n            \n            # Extract embeddings for both utterances\n            embeddings1 = model.extract_embedding(features1)\n            embeddings2 = model.extract_embedding(features2)\n            \n            # Compute cosine similarity\n            similarities = F.cosine_similarity(embeddings1, embeddings2)\n            \n            all_scores.append(similarities.cpu())\n            all_labels.append(labels.cpu())\n    \n    # Concatenate all scores and labels\n    all_scores = torch.cat(all_scores).numpy()\n    all_labels = torch.cat(all_labels).numpy()\n    \n    # Compute EER\n    eer, threshold = compute_eer(all_scores, all_labels)\n    return eer, threshold\n\n# Training loop\nnum_epochs = config['training']['num_epochs']\nbest_val_eer = float('inf')\nbest_epoch = 0\nbest_state_dict = None\n\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    train_loss = 0.0\n    for batch_idx, batch in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} (Train)')):\n        features = batch['features'].to(device)\n        speaker_ids = batch['speaker_ids'].to(device)\n        \n        optimizer.zero_grad()\n        logits = model(features, speaker_ids)\n        loss = criterion(logits, speaker_ids)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n        # Log batch-level metrics\n        wandb.log({\n            'batch': epoch * len(train_loader) + batch_idx,\n            'batch_loss': loss.item()\n        })\n    \n    train_loss /= len(train_loader)\n    \n    # Validation phase\n    val_easy_eer, easy_threshold = validate_eer(model, val_easy_loader, device)\n    val_hard_eer, hard_threshold = validate_eer(model, val_hard_loader, device)\n    \n    # Average EER from both validation sets\n    avg_val_eer = (val_easy_eer + val_hard_eer) / 2\n    \n    # Log epoch-level metrics\n    wandb.log({\n        'epoch': epoch + 1,\n        'train_loss': train_loss,\n        'val_easy_eer': val_easy_eer * 100,  # Convert to percentage\n        'val_hard_eer': val_hard_eer * 100,  # Convert to percentage\n        'avg_val_eer': avg_val_eer * 100,    # Convert to percentage\n        'easy_threshold': easy_threshold,\n        'hard_threshold': hard_threshold,\n        'learning_rate': scheduler.get_last_lr()[0]\n    })\n    \n    print(f'Epoch {epoch+1}/{num_epochs}:')\n    print(f'Training Loss: {train_loss:.4f}')\n    print(f'Validation Easy EER: {val_easy_eer*100:.2f}% (threshold: {easy_threshold:.3f})')\n    print(f'Validation Hard EER: {val_hard_eer*100:.2f}% (threshold: {hard_threshold:.3f})')\n    print(f'Average Validation EER: {avg_val_eer*100:.2f}%')\n    \n    # Save best model based on average EER\n    if avg_val_eer < best_val_eer:\n        best_val_eer = avg_val_eer\n        best_epoch = epoch + 1\n        best_state_dict = model.state_dict().copy()\n        checkpoint = {\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n            'best_val_eer': best_val_eer,\n            'easy_threshold': easy_threshold,\n            'hard_threshold': hard_threshold\n        }\n        torch.save(checkpoint, f'{config[\"paths\"][\"checkpoint_dir\"]}/best_model.pth')\n        # Save model to wandb\n        wandb.save(f'{config[\"paths\"][\"checkpoint_dir\"]}/best_model.pth')\n        print(f'New best model saved! (Average EER: {best_val_eer*100:.2f}%)')\n    \n    # Learning rate scheduling\n    scheduler.step()\n\nprint(f'\\nTraining completed!')\nprint(f'Best validation EER: {best_val_eer*100:.2f}% at epoch {best_epoch}')\n\n# Log final best metrics\nwandb.run.summary.update({\n    'best_val_eer': best_val_eer * 100,  # Convert to percentage\n    'best_epoch': best_epoch\n})\n\n# Load best model for final use\ncheckpoint = torch.load(f'{config[\"paths\"][\"checkpoint_dir\"]}/best_model.pth')\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel.eval()\n\n# Close wandb run\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:49:41.912160Z","iopub.execute_input":"2025-06-01T19:49:41.912417Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/150 (Train):   0%|          | 0/1890 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"id":"39198626","cell_type":"code","source":"# Save the final model\nfinal_model_path = '/kaggle/working/final_model.pth'\ntorch.save(model.state_dict(), final_model_path)\nprint(f\"Training completed and model saved to {final_model_path}!\")\nprint(f\"Best validation EER: {best_val_eer*100:.2f}% at epoch {best_epoch}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:38.073639Z","iopub.status.idle":"2025-06-01T19:47:38.074090Z","shell.execute_reply.started":"2025-06-01T19:47:38.073846Z","shell.execute_reply":"2025-06-01T19:47:38.073863Z"}},"outputs":[],"execution_count":null},{"id":"15fba502","cell_type":"markdown","source":"## Dataset Augmentation Setup\n\n### MUSAN Dataset Configuration (Optional)\n\nThis section configures audio augmentation using the MUSAN dataset. The training will work without MUSAN, but having it enables better model robustness through:\n- Background noise augmentation\n- Music interference augmentation\n- Speech babble noise augmentation\n\nIf you don't have the MUSAN dataset:\n1. Visit http://www.openslr.org/17/\n2. Download and extract to `/kaggle/input/musan-dataset/`","metadata":{}},{"id":"f8a9882b","cell_type":"markdown","source":"## Optional: Augmentation Quality Validation\n\nThis section helps validate the quality of audio augmentation by visualizing and analyzing:\n1. Waveforms before/after augmentation\n2. Spectrograms to verify frequency characteristics\n3. Signal-to-Noise Ratio (SNR) statistics\n4. Augmentation type distribution\n\nYou can skip this section if not using MUSAN augmentation.","metadata":{}},{"id":"ca490cc1","cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import librosa\n# import librosa.display\n# import numpy as np\n# from utils.augment import AudioAugmenter\n\n# # Create audio augmenter with our configuration\n# audio_augmenter = AudioAugmenter(\n#     sample_rate=config['audio']['sample_rate'],\n#     enabled=True,\n#     speed_perturb=augment_config.get('speed_perturb', True),\n#     noise_prob=augment_config.get('noise_prob', 0.5),\n#     noise_snr_range=augment_config['noise_snr_range'],  # Fixed parameter name\n#     reverb_prob=augment_config.get('reverb_prob', 0.5),\n#     musan_path=augment_config.get('musan_path'),\n#     noise_types=augment_config['noise_types']\n# )\n\n# def plot_audio_comparison(original, augmented, sr, title=\"Audio Comparison\"):\n#     fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n#     fig.suptitle(title)\n    \n#     # Original waveform\n#     axes[0,0].plot(original)\n#     axes[0,0].set_title('Original Waveform')\n    \n#     # Augmented waveform\n#     axes[0,1].plot(augmented)\n#     axes[0,1].set_title('Augmented Waveform')\n    \n#     # Original spectrogram\n#     D = librosa.amplitude_to_db(np.abs(librosa.stft(original)), ref=np.max)\n#     librosa.display.specshow(D, y_axis='log', x_axis='time', ax=axes[1,0])\n#     axes[1,0].set_title('Original Spectrogram')\n    \n#     # Augmented spectrogram\n#     D = librosa.amplitude_to_db(np.abs(librosa.stft(augmented)), ref=np.max)\n#     librosa.display.specshow(D, y_axis='log', x_axis='time', ax=axes[1,1])\n#     axes[1,1].set_title('Augmented Spectrogram')\n    \n#     plt.tight_layout()\n#     return fig\n\n# def compute_snr(original, noisy):\n#     noise = noisy - original\n#     signal_power = np.mean(original ** 2)\n#     noise_power = np.mean(noise ** 2)\n#     snr = 10 * np.log10(signal_power / noise_power)\n#     return snr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:38.076414Z","iopub.status.idle":"2025-06-01T19:47:38.076948Z","shell.execute_reply.started":"2025-06-01T19:47:38.076654Z","shell.execute_reply":"2025-06-01T19:47:38.076672Z"}},"outputs":[],"execution_count":null},{"id":"5513484e","cell_type":"code","source":"# # Get a sample from the training dataset\n# sample_idx = 0\n# sample = train_dataset[sample_idx]\n# original_audio = sample['audio']\n\n# # Test different noise types\n# noise_types = ['background', 'music', 'babble']\n# figs = []\n\n# for noise_type in noise_types:\n#     # Apply specific noise augmentation\n#     augmented_audio = audio_augmenter.apply_noise(\n#         original_audio.numpy(), \n#         noise_type=noise_type,\n#         snr=np.random.uniform(*augment_config['snr_range'])\n#     )\n    \n#     # Calculate actual SNR\n#     actual_snr = compute_snr(original_audio.numpy(), augmented_audio)\n    \n#     # Plot comparison\n#     fig = plot_audio_comparison(\n#         original_audio.numpy(),\n#         augmented_audio,\n#         config['audio']['sample_rate'],\n#         f'Audio Comparison - {noise_type.capitalize()} Noise (SNR: {actual_snr:.2f} dB)'\n#     )\n#     figs.append(fig)\n    \n#     # Log augmented audio sample to wandb\n#     wandb.log({\n#         f'audio_samples/{noise_type}': wandb.Audio(\n#             augmented_audio,\n#             sample_rate=config['audio']['sample_rate'],\n#             caption=f'{noise_type.capitalize()} noise augmentation'\n#         )\n#     })\n\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:38.078938Z","iopub.status.idle":"2025-06-01T19:47:38.079371Z","shell.execute_reply.started":"2025-06-01T19:47:38.079150Z","shell.execute_reply":"2025-06-01T19:47:38.079168Z"}},"outputs":[],"execution_count":null},{"id":"ec0faf9b","cell_type":"code","source":"# # Validate augmentation statistics\n# def validate_augmentation_stats(dataset, num_samples=100):\n#     snr_values = []\n#     noise_type_counts = {noise_type: 0 for noise_type in noise_types}\n#     total_augmented = 0\n\n#     for i in range(num_samples):\n#         sample = dataset[i]\n#         original_audio = sample['audio']\n        \n#         # Apply random augmentation as per training\n#         if np.random.random() < augment_config['noise_prob']:\n#             noise_type = np.random.choice(noise_types, p=[info['prob'] for info in augment_config['noise_types'].values()])\n#             snr = np.random.uniform(*augment_config['snr_range'])\n            \n#             augmented_audio = audio_augmenter.apply_noise(original_audio.numpy(), noise_type=noise_type, snr=snr)\n#             actual_snr = compute_snr(original_audio.numpy(), augmented_audio)\n            \n#             snr_values.append(actual_snr)\n#             noise_type_counts[noise_type] += 1\n#             total_augmented += 1\n    \n#     # Print statistics\n#     print(f\"Augmentation Statistics (over {num_samples} samples):\")\n#     print(f\"Total augmented: {total_augmented}/{num_samples} ({total_augmented/num_samples*100:.1f}%)\")\n#     print(\"\\nNoise type distribution:\")\n#     for noise_type, count in noise_type_counts.items():\n#         print(f\"{noise_type}: {count}/{total_augmented} ({count/total_augmented*100:.1f}% of augmented)\")\n    \n#     if snr_values:\n#         print(\"\\nSNR statistics:\")\n#         print(f\"Mean SNR: {np.mean(snr_values):.2f} dB\")\n#         print(f\"Std SNR: {np.std(snr_values):.2f} dB\")\n#         print(f\"Min SNR: {np.min(snr_values):.2f} dB\")\n#         print(f\"Max SNR: {np.max(snr_values):.2f} dB\")\n        \n#         # Log statistics to wandb\n#         wandb.log({\n#             'augmentation/mean_snr': np.mean(snr_values),\n#             'augmentation/std_snr': np.std(snr_values),\n#             'augmentation/augmentation_rate': total_augmented/num_samples\n#         })\n\n# # Run validation\n# validate_augmentation_stats(train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:38.083601Z","iopub.status.idle":"2025-06-01T19:47:38.084109Z","shell.execute_reply.started":"2025-06-01T19:47:38.083826Z","shell.execute_reply":"2025-06-01T19:47:38.083845Z"}},"outputs":[],"execution_count":null},{"id":"747d220a","cell_type":"markdown","source":"### MUSAN Dataset Structure\n\nThe MUSAN dataset should be organized in the following structure at `/kaggle/input/musan-dataset/musan/`:\n\n```\nmusan/\n├── noise/\n│   ├── free-sound/\n│   └── sound-bible/\n├── music/\n│   ├── fma/\n│   ├── fma-western-art/\n│   ├── hd-classical/\n│   ├── jamendo/\n│   ├── rfm/\n└── speech/\n    ├── librivox/\n    └── us-gov/\n```\n\nYou can download the MUSAN dataset from:\n1. Visit http://www.openslr.org/17/\n2. Download the tar file (about 14GB compressed)\n3. Extract it to `/kaggle/input/musan-dataset/`\n\nThe dataset contains:\n- **noise**: Various background noises and sound effects\n- **music**: Different genres and styles of music recordings\n- **speech**: Speech recordings from various sources\n\nEach category is used differently in our augmentation pipeline:\n- Background noise: Simulates real-world environments\n- Music: Creates challenging interference conditions\n- Speech: Generates realistic babble noise with multiple overlapped speakers","metadata":{}},{"id":"668ff32b","cell_type":"code","source":"# # First, let's verify the MUSAN dataset structure\n# def verify_musan_structure(root_path):\n#     expected_structure = {\n#         'noise': ['free-sound', 'sound-bible'],\n#         'music': ['fma', 'fma-western-art', 'hd-classical', 'jamendo', 'rfm'],\n#         'speech': ['librivox', 'us-gov']\n#     }\n    \n#     all_valid = True\n#     for category, subdirs in expected_structure.items():\n#         category_path = os.path.join(root_path, category)\n#         if not os.path.exists(category_path):\n#             logger.error(f\"Missing category directory: {category}\")\n#             all_valid = False\n#             continue\n            \n#         for subdir in subdirs:\n#             subdir_path = os.path.join(category_path, subdir)\n#             if not os.path.exists(subdir_path):\n#                 logger.warning(f\"Missing subdirectory: {category}/{subdir}\")\n#                 all_valid = False\n#             else:\n#                 # Count files to verify content\n#                 files = [f for f in os.listdir(subdir_path) if f.endswith('.wav')]\n#                 logger.info(f\"Found {len(files)} .wav files in {category}/{subdir}\")\n    \n#     return all_valid\n\n# # Verify MUSAN dataset structure\n# musan_valid = verify_musan_structure(musan_config['data_root'])\n# if not musan_valid:\n#     logger.warning(\"MUSAN dataset structure is incomplete. Some augmentations may not work as expected.\")\n# else:\n#     logger.info(\"MUSAN dataset structure verified successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T19:47:38.084877Z","iopub.status.idle":"2025-06-01T19:47:38.085384Z","shell.execute_reply.started":"2025-06-01T19:47:38.085133Z","shell.execute_reply":"2025-06-01T19:47:38.085156Z"}},"outputs":[],"execution_count":null}]}