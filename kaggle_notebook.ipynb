{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba995531",
   "metadata": {},
   "source": [
    "# Speaker Verification with ECAPA-TDNN on Kaggle GPU\n",
    "\n",
    "This notebook implements speaker verification using the ECAPA-TDNN architecture on Kaggle's GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a7752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torchaudio==0.9.0 PyYAML==5.4.1 soundfile==0.10.3 librosa==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f54167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup working directory and clone repository\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Start fresh in working directory\n",
    "%cd /kaggle/working\n",
    "!rm -rf speaker-verification\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/mapotofu40/speaker-verification.git\n",
    "\n",
    "# Move config.py to avoid name conflict\n",
    "!mv speaker-verification/config.py speaker-verification/global_config.py\n",
    "\n",
    "# Set up Python path\n",
    "project_dir = Path('/kaggle/working/speaker-verification').absolute()\n",
    "if str(project_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(project_dir))\n",
    "\n",
    "print(\"\\nDirectory structure:\")\n",
    "!ls -R speaker-verification/\n",
    "\n",
    "print(f\"\\nProject directory: {project_dir}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5bba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "\n",
    "# Clear sys.path of duplicates\n",
    "sys.path = list(dict.fromkeys(sys.path))\n",
    "\n",
    "# Verify imports work\n",
    "try:\n",
    "    from config.defaults import BASE_CONFIG\n",
    "    from models.ecapa_tdnn import SpeakerVerificationModel\n",
    "    from models.feature_extractor import FeatureExtractor\n",
    "    from utils.data import VietnamCelebDataset, collate_fn\n",
    "    from utils.training import train_model\n",
    "    from torch.utils.data import DataLoader\n",
    "    print(\"All modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"\\nCurrent directory structure:\")\n",
    "    !pwd\n",
    "    !ls -R\n",
    "    print(f\"\\nPython path:\")\n",
    "    for p in sys.path:\n",
    "        print(f\"  {p}\")\n",
    "    raise\n",
    "\n",
    "# Verify GPU availability\n",
    "print(f\"\\nGPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec11454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths for Kaggle\n",
    "config = BASE_CONFIG.copy()\n",
    "config['paths'].update({\n",
    "    'checkpoint_dir': '/kaggle/working/checkpoints',\n",
    "    'log_dir': '/kaggle/working/logs',\n",
    "    'cache_dir': '/kaggle/working/cache'\n",
    "})\n",
    "\n",
    "# Create necessary directories\n",
    "for path in config['paths'].values():\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ecb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "data_config = {\n",
    "    'data_root': '/kaggle/input/your-dataset/data',  # Update with your dataset path\n",
    "    'metadata_file': '/kaggle/input/your-dataset/metadata.tsv',\n",
    "    'utterance_file': '/kaggle/input/your-dataset/utterances.txt'\n",
    "}\n",
    "\n",
    "# Create feature extractor\n",
    "feature_extractor = FeatureExtractor(\n",
    "    sample_rate=config['audio']['sample_rate'],\n",
    "    n_mels=config['audio']['n_mels']\n",
    ")\n",
    "\n",
    "# Create dataset\n",
    "dataset = VietnamCelebDataset(\n",
    "    data_root=data_config['data_root'],\n",
    "    metadata_file=data_config['metadata_file'],\n",
    "    utterance_file=data_config['utterance_file'],\n",
    "    feature_extractor=feature_extractor,\n",
    "    cache_dir=config['paths']['cache_dir'],\n",
    "    use_cache=config['cache']['enabled']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,  # Reduce for Kaggle\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2,  # Reduce for Kaggle\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f34d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = SpeakerVerificationModel(\n",
    "    input_dim=config['audio']['n_mels'],\n",
    "    channels=config['model']['channels'],\n",
    "    embedding_dim=config['model']['embedding_dim'],\n",
    "    num_blocks=config['model']['num_blocks'],\n",
    "    num_speakers=len(dataset.speaker_to_idx)\n",
    ")\n",
    "\n",
    "# Train model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=config['training']['num_epochs'],\n",
    "    learning_rate=config['training']['learning_rate'],\n",
    "    device=device,\n",
    "    checkpoint_dir=config['paths']['checkpoint_dir']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39198626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "torch.save(model.state_dict(), '/kaggle/working/final_model.pth')\n",
    "print(\"Training completed and model saved!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
